\section{Formal specification of SCITE}

First, we will formalize the observed phenomenon of mutations. This formalization is based on the original framework by Jahn et al. \cite{tree2016}, but with improved soundness and more details that we require both to formally describe \ac{SCITE} and to prove the correctness of our implementation. 

\begin{definition}
    \label{def:mutmatrix}
    Let $n, m \in \mathbb{N}$ be the considered number of cells and genes, respectively. Then, we define the random variables $E$ and $D$ with $\mathrm{im}(E) \subseteq \{0,1\}^{n \times m}$ and $\mathrm{im}(D) \subseteq \{0, 1, 2\}^{n \times m}$. $E$ is the true mutation matrix that describes the actual state of the cells, and $D$ is the observed, erroneous mutation matrix. Let also $\alpha \in (0,1)$ be the probability of false positives and $\beta \in (0,1)$ be the probability of false negatives. We then assume the following for all $i \leq n, j \leq m$:
    \begin{align*}
        \mathbb{P}(D_{i,j} = 1 \mid E_{i,j} = 0 \wedge D_{i,j} \neq 2) &:= \alpha & \mathbb{P}(D_{i,j} = 0\mid E_{i,j} = 1 \wedge D_{i,j} \neq 2) &:= \beta \\
        \mathbb{P}(D_{i,j} = 0 \mid E_{i,j} = 0 \wedge D_{i,j} \neq 2) &:= (1-\alpha) & \mathbb{P}(D_{i,j} = 1 \mid E_{i,j} = 1 \wedge D_{i,j} \neq 2) &:= (1-\beta)
    \end{align*}
    The additional prior $D_{i,j} \neq 2$ is not present in the original formalization, but technically necessary since we would otherwise have $\mathbb{P}(D_{i,j} = 2 \mid E_{i,j} = e) = 0$ for all $e \in \{0,1\}$, which is not useful.
\end{definition}

\begin{definition}
    \label{def:likelihood}
    First, we define the local likelihood function $\lambda$ as follows:
    \begin{align*}
        \lambda_d: \{0, 1, 2\} \times \{0, 1\} \rightarrow (0, 1), (d, e) &\mapsto \begin{cases}
            \mathbb{P}(D_{i,j} = d \mid E_{i,j} = e \wedge D_{i,j} \neq 2) & d \neq 2 \\
            1 & d = 2 \\
        \end{cases} \\
        &= \begin{cases}
            1-\alpha & d = 0 \wedge e = 0 \\
            \alpha & d = 1 \wedge e = 0 \\
            \beta & d = 0 \wedge e = 1 \\
            1-\beta & d = 1 \wedge e = 1 \\
            1 & d = 2
        \end{cases}
    \end{align*}
    We make the distinction between $d = 2$ and $d \neq 2$ since we are not interested in lost data, with the underlying assumption that data loss is independent of the true mutation status of a cell. This distinction is not present in the original formalization, but it is present in the original implementation. 

    Given an observed mutation data matrix $d \in \{0,1,2\}^{n \times m}$, we then define the global likelihood function as follows:
    \begin{align*}
        \Lambda_d : \{0,1\}^{n \times m} \rightarrow (0,1), e \mapsto \prod_{i = 0}^n \prod_{j = 0}^m \lambda(d_{i,j}, e_{i,j})
    \end{align*}
\end{definition}

\begin{definition}
    \label{def:mutation_tree}
    Let $m \in \mathbb{N}$ be the number of considered genes. A mutation tree is a rooted, directed tree $T = (V, E, r)$ with $V = \{1, 2, 3, \dots, m, r\}$, $|V| = m+1$.
\end{definition}

\begin{definition}
    \label{def:reachability}
    Let $T = (V, E)$ be a tree and $v, w \in V$. $w$ is reachable from $v$, formally $v \leadsto_T w$, iff there is a path $p = (v, \dots, w)$ in $T$.
\end{definition}

\begin{definition}
    \label{def:attachment}
    Let $n, m \in \mathbb{N}$ be the considered number of cells and genes, respectively, and $T = (V, E, r)$ a mutation tree. An attachment function is a function $\sigma: \{1, \dots, n\} \rightarrow V$.
\end{definition}

\begin{definition}
    \label{def:induced_mutmatrix}
    Let $n, m \in \mathbb{N}$ be the considered number of cells and genes, respectively, $T$ a mutation tree and $\sigma$ an attachment function. We define the mutation matrix $e_{T, \sigma} \in \{0,1\}^{n \times m}$ induced by the mutation matrix and attachment function as follows:
    \begin{align*}
        \forall i \leq n, j \leq m: (e_{T, \sigma})_{i,j} := \begin{cases}
            1 & j \leadsto_T \sigma(i) \\
            0 & \mathrm{else}
        \end{cases}
    \end{align*}
    This means that a cell $i$ has a mutation $j$ iff $j$ is an ancestor of its attachment node $\sigma(i)$.
\end{definition}

\todo[inline]{Insert an example here.}

\begin{definition}[The SCITE problem]
    \label{def:scite_problem}
    Let $n, m \in \mathbb{N}$ be the considered number of cells and genes, respectively, and $d \in \{0,1\}^{n \times m}$ an observed mutation matrix. The \ac{SCITE} problem is: Find a mutation tree $T$ and an attachment function $\sigma$ so that $\Lambda_d(e_{T, \sigma})$ is maximal.
\end{definition}

\begin{example}
    \label{exmpl:scite_problem}
    Let's have a constructed example: We consider $n = 4$ cells and $m = 4$ genes. We assume that the true, underlying mutation tree $T$ and attachments $\sigma$ look like this:
    \todo[inline]{Draw example tree}
    Therefore, this gives us the following true mutation matrix:
    \begin{align*}
        e_{T, \sigma} &= \begin{pmatrix}
            1 & 0 & 0 & 0 \\
            0 & 1 & 0 & 0 \\
            1 & 1 & 0 & 0 \\
            0 & 0 & 1 & 1 \\
        \end{pmatrix}
    \end{align*}
    In this example, we assume that $(\alpha, \beta) = (0.01, 0.4)$ and that matrix entries are set as missing with a probability of 0.25, after the false-positive and -negative errors are decided. This is not necessarily the case for all inputs and the algorithms do not work with this assumption, but we can use this model to generate an observed mutation matrix $d$, like this one:
    \begin{align*}
        d &= \begin{pmatrix}
            1 & 0 & 0 & 0 \\
            0 & 2 & 0 & 2 \\
            1 & 1 & 2 & 0 \\
            0 & 0 & 0 & 1 \\
        \end{pmatrix}
    \end{align*}
    Now, we can compute the likelihood of the underlying mutation tree and attachment:
    \begin{align*}
        \Lambda_d(e_{T, \sigma}) = (1-\alpha)^{8} \cdot \alpha^{0} \cdot (1-\beta)^{4} \cdot \beta^{1} &\approx 0.05 \\
        &\approx \exp(-3.04)
    \end{align*}
    However, if you attach cell number two to gene two instead, you get the following tree:
    \todo[inline]{Modified example graph}
    with the following true mutation matrix:
    \begin{align*}
        e_{T, \sigma'} = \begin{pmatrix}
            1 & 0 & 0 & 0 \\
            0 & 1 & 0 & 0 \\
            1 & 1 & 1 & 0 \\
            0 & 0 & 0 & 1 \\
        \end{pmatrix}
    \end{align*}
    and the following likelihood:
    \begin{align*}
        \Lambda_d(e_{T, \sigma'}) = (1-\alpha)^{9} \cdot \alpha^{0} \cdot (1-\beta)^{4} \cdot \beta^{0} &\approx 0.12 \\
        &\approx \exp(-2.13) 
    \end{align*}
    This is one of the solutions found by \ac{SCITE} and it shows that the true, underlying mutation tree and attachment function is not necessarily the most likely one.
\end{example}

Next, we have a lemma that shows that it is not necessary to search for the maximal attachment function given a mutation tree:

\begin{lemma}[\cite{tree2016}]
    \label{lem:max_attachment}
    Let $n, m \in \mathbb{N}$ be the considered number of cells and genes, respectively, $d \in \{0,1\}^{n \times m}$ an observed mutation matrix, and $T$ a mutation tree. We define:
    \begin{align*}
        \sigma_{\max, T}: \{1, \dots, n\} \rightarrow V, i \mapsto \argmax_{v \in V} \prod_{j = 1}^m \lambda \left(d_{i,j}, \begin{cases}
            1 & j \leadsto_T v \\
            0 & \mathrm{else} \\
        \end{cases}\right)
    \end{align*}
    $\sigma_{\max, T}$ maximizes $\Lambda_d (e_{T, \sigma})$ among all $\sigma: \{1, \dots, n\} \rightarrow V$.
\end{lemma}

Informally, $\sigma_{\max, T}$ picks the attachment node for every cell that maximizes its local likelihood. This lemma is already assumed to be true in the original SCITE paper \cite{tree2016}. Therefore, we see no need to prove it. However, it means that SCITE only needs to try different trees, not every tree-attachment combination, and we can simply write $\Lambda_d(T)$ instead of $\Lambda_d(e_{T, \sigma_{\max, T}})$ to express the likelihood of a mutation tree. 

\todo[inline]{Define the SCITE chain as a Markov chain}

\begin{definition}[Proposal of new trees, \cite{tree2016}] We define the algorithm to propose a new tree as follows:
    \begin{algorithmic}
        \Function{ProposeChange}{$T$}
            \State $(V, E, r) \leftarrow T$
            \State $\mathrm{move} \leftarrow \text{sample uniformly from } \{\text{``swap nodes''}, \text{``prune and reattach''}, \text{``swap subtrees''}\}$
            \If{$\mathrm{move} = \text{``swap nodes''}$}
                \State $v \leftarrow \text{sample uniformly from } V \setminus \{r\}$
                \State $w \leftarrow \text{sample uniformly from } V \setminus \{r, v\}$
                \State $E' \leftarrow \{(w, x) : (v, x) \in E \wedge x \neq w\} \cup \{(v, x) : (w, x) \in E \wedge x \neq v\}$
                \State $E' \leftarrow E' \cup \{(x, y) \in E: \{x, y\} \cap \{v, w\} \neq \emptyset\}\}$
                \If{$(v, w) \in E$}
                    \State $E' \leftarrow E' \cup \{(w, v), (p(v), w)\}$
                \ElsIf{$(w, v) \in E$}
                    \State $E' \leftarrow E' \cup \{(v, w), (p(w), v)\}$
                \Else
                    \State $E' \leftarrow E' \cup \{(p(w), v), (p(v), w)\}$
                \EndIf
                \State $f_\mathrm{correction} \leftarrow 1$
            \ElsIf{$\mathrm{move} = \text{``prune and reattach''}$}
                \State $v \leftarrow \text{sample uniformly from } V \setminus \{r\}$
                \State $w \leftarrow \text{sample uniformly from } \{w \in V : v \not\leadsto_T w\}$
                \State $E' \leftarrow \left(E \setminus \{(p(v), v)\}\right)  \cup \{(w, v)\}$
                \State $f_\mathrm{correction} \leftarrow 1$
            \ElsIf{$\mathrm{move} = \text{``swap subtrees''}$}
                \State $v \leftarrow \text{sample uniformly from } V \setminus \{r\}$
                \State $w \leftarrow \text{sample uniformly from } V \setminus \{r, v\}$
                \If{$v \leadsto_T w$}
                    \State $v, w \leftarrow w, v$
                \EndIf
                \If{$w \leadsto_T v$}
                    \State $t \leftarrow \text{sample uniformly from } \{x \in V: v \leadsto_T x\}$
                    \State $f_\mathrm{correction} \leftarrow \frac{|\{x \in V : v \leadsto_T x\}|}{|\{x \in V : w \leadsto_T x\}|}$
                \Else
                    \State $t \leftarrow p(v)$
                    \State $f_\mathrm{correction} \leftarrow 1$
                \EndIf
                \State $E' \leftarrow (E \setminus \{(p(v), v)\}) \cup \{(p(w), v)\}$ 
                \State $E' \leftarrow (E' \setminus \{(p(w), w)\}) \cup \{(t, w)\}$
            \EndIf
            \State \Return $(V, E', r), f_\mathrm{correction}$
        \EndFunction
    \end{algorithmic}
\end{definition}

We will also continue to write $\Lambda_d(T)$ instead of $\Lambda_d(e_{T, \sigma_{\max, T}})$. With everything in place, we can now formally describe the \ac{SCITE} algorithm:

\begin{definition}[The general SCITE algorithm, \cite{tree2016}] We define the \ac{SCITE} algorithm as follows:
    \begin{algorithmic}
        \Function{SCITE}{$n_\mathrm{chains} \in \mathbb{N}, n_\mathrm{steps} \in \mathbb{N}, d \in \{0,1,2\}^{n \times m}$}
            \State $T_\mathrm{best} \leftarrow \text{sample random mutation tree}$
            \State $s_\mathrm{best} \leftarrow \Lambda_d(T_\mathrm{best})$
            \ForAll{$i_\mathrm{chain} \leq n_\mathrm{chains}$}
                \State $T_\mathrm{current} \leftarrow \text{sample random mutation tree}$
                \State $s_\mathrm{current} \leftarrow \Lambda_d(T_\mathrm{current})$
                \ForAll{$i_\mathrm{step} \leq n_\mathrm{steps}$}
                    \State $T_\mathrm{proposed}, f_\mathrm{correction} \leftarrow \textsc{ProposeChange}(T_\mathrm{current})$
                    \State $s_\mathrm{proposed} \leftarrow \Lambda_d(T_\mathrm{proposed})$
                    \State $p_\mathrm{acceptance} \leftarrow f_\mathrm{correction} \cdot \frac{s_\mathrm{proposed}}{s_\mathrm{current}}$
                    \If{accept with probability $p_\mathrm{acceptance}$}
                        \State $T_\mathrm{current}, s_\mathrm{current} \leftarrow T_\mathrm{proposed}, s_\mathrm{proposed}$
                    \EndIf
                    \If{$s_\mathrm{proposed} > s_\mathrm{best}$}
                        \State $T_\mathrm{best}, s_\mathrm{best} \leftarrow T_\mathrm{proposed}, s_\mathrm{proposed}$
                    \EndIf
                \EndFor
            \EndFor
        \EndFunction
    \end{algorithmic}
\end{definition}