\chapter{Conclusion}
\label{ch:conclusion}

\ac{ffSCITE} reaches the goal of being an implementation of the \ac{SCITE} algorithm for \acp{FPGA} with higher throughput than the reference implementation by Jahn et al. \cite{tree2016}. This algorithm computes the most likely mutation history of a group of tumor cells, given noisy information about their mutation status.

Our biggest contribution is an improvement to the mutation tree encoding: The reference implementation uses parent vectors as the canonical data structure, which contain the parent of every node in the tree. However, it also uses ancestor matrices to analyze the mutation tree, which denote whether there is a path from one node in the tree to another. These ancestor matrices are constructed from parent vectors and this operation is not practical on \acp{FPGA}. We, therefore, developed algorithms to reconstruct the mutation tree from an ancestor matrix and to compute the resulting ancestor matrix of a tree modification based on the old one. These algorithms are impractical on \acp{CPU} but work well on \acp{FPGA} due to their flexibility regarding custom logic, and due to this contribution, our implementation can work exclusively on ancestor matrices and avoid constructing ancestor matrices on the device.

Additionally, we reformulated the algorithm to compute a mutation tree's likelihood: The reference implementation uses two different implementations with different precisions to improve performance, but since \ac{ffSCITE} would not benefit from computing it twice, we based our formulation on the fast method. The likelihood computation algorithm can be described as a mapping step followed by a two-dimensional reduction. The original formulation executed the reductions together with the mapping operation, which created too many loop-carried dependencies and resulted in a structurally underperforming design. We, therefore, split the mapping and the two reductions into separate loops and used loop unrolling to improve the loop's throughput at the cost of higher resource usage.

Lastly, we also dealt with issues regarding random number generation: We used \acfp{URNG} and distribution algorithms from the C++ standard library and Intel's oneDPL to reduce development time. While these implementations work correctly on \acp{FPGA}, they were originally designed for \acp{CPU}. We especially faced issues with our \ac{URNG}, the Minstd \ac{URNG} \cite{park1988random}, since it uses 64-bit integer multiply and remainder operations. These operations have a high resource usage and latency, and since their output is supposed to appear random, they create a data dependency that leads to an increased \acf{II} for the loop that uses them. Therefore, we isolated the random draws into a separate kernel and reduced the \ac{II} of its main loop to a level below the current bottleneck.

The previous optimizations resulted in a macro-pipeline where different components work independently from one another to execute a chain step. This pipeline needs to be filled at all times to maximize the mean throughput. We did this by filling the pipeline with initial chain states once, feeding the emitted states back after a chain step, and replacing them with new initial states once the chains are complete. Our scheme ensures that the pipeline is always filled and also simplifies and minimizes interactions with off-chip memory, which additionally reduces compilation times and potentially increases energy efficiency.

The resulting chip design utilizes up to 69\% of the resources available on our target device, a Bittware 520N card with an Intel Stratix 10 GX 2800 \ac{FPGA}. Our design achieves a constant throughput of 577.8 thousand chain steps per second and is bottlenecked by the mapping step of the likelihood computation, as we have predicted based on the synthesis report. Compared to the reference implementation run on one of Noctua 2's compute nodes, our implementation has up to 8.6 times higher throughput. However, our implementation likely has a lower throughput than the one by Ernst et al. \cite{ernst2020Performance}, which is an optimized version of the \ac{CPU} reference implementation.

Our last goal was to verify that our implementation produces results of similar quality compared to the reference implementation. Since the \ac{SCITE} algorithm is not deterministic and our optimizations did not allow us to implement a bit-perfect copy of the reference, we had to use a statistical test to verify our solution quality. We used the \acf{TOST} procedure \cite{schuirmann1987comparison} to define an equivalence test that compares two implementations of the \ac{SCITE} algorithm, and our implementation is equivalent to the reference implementation with a significance level of 2\%.

\input{chapters/conclusion/open_directions.tex}