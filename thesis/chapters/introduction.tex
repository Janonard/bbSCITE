\chapter{Introduction}
\label{ch:introduction}

\section{Problem Formulation}

The input is a function $D: C \times G \rightarrow \{0, 1, ?\}$, where $C$ is the set of sampled cells and $G$ is a set of genome positions. If for a cell $c \in C$ and a genome position $g \in G$ we have $D(c, g) = 1$, the genome position $g$ has been observed as mutated in cell $c$, and if we have $D(c, g) = 0$, the genome position $g$ has been observed in it's common form. There is also a third option $D(c, g) = ?$, which means that the genome position has not been found at all and no statement could be made whether it is mutated or not. As the existance of the $?$ option may indicate, this function is noisy and may contain errors. It is assumed that errors occur independently from each other and if we let $E: C \times G \rightarrow \{0, 1\}$ be the true state of the cells, we have
\begin{align*}
    \mathbb{P}(D(c, g) = 0 \mid E(c, g) = 0) &= 1 - \alpha & \mathbb{P}(D(c, g) = 1 \mid E(c, g) = 0) &= \alpha \\
    \mathbb{P}(D(c, g) = 0 \mid E(c, g) = 1) &= \beta & \mathbb{P}(D(c, g) = 1 \mid E(c, g) = 1) &= 1 - \beta
\end{align*}
for some error rates $\alpha, \beta \in (0, 1)$. Error modeling for $D(c, g) = ?$ is not given by the authors. Missing data is always ignored in probability calculations.

The goal now is to find a mutation tree, a cell attachment and error rates with a high likelihood of being correct. A mutation tree is a rooted tree $T = (G \cup \{r\}, E, r)$ where $r$ is the root of the tree and the other nodes are genome positions. It expresses that the mutation of $g \in G$ has occured after all it's ancestors, prior to it's successors and independently from all unrelated genome positions. A cell attachment is a simple function $\sigma: C \rightarrow G$ and expresses that a cell $c \in C$ has the mutation status just after $\sigma(c)$ was mutated. Therefore, a cell $c$ has mutations at all genome positions that are ancestors of $\sigma(c)$, but at no other positions. This model is sensible since the authors of \ac{scite} make the ``infinite sites'' assumption, which states that a genome position mutates exactly once in the complete history of the tumor and does not mutate back.

With the mutation tree $T$ and a cell attachment $\sigma$, we can now build a function $e_{(T, \sigma)}: C \times G \rightarrow \{0, 1\}$ that expresses the made statements of the cell's true mutation status. Formally, we set
\begin{align*}
    e_{(T, \sigma)}(c, g) &:= \begin{cases}
        1 & g \in \mathrm{Anc}_T(\sigma(c)) \\
        0 & \text{else} \\
    \end{cases}
\end{align*}
where $\mathrm{Anc}_T(g)$ is the set of ancestors of a genome position $g \in G$ with respect to $T$. Therefore, the likelihood of a tree and cell attachment given the observed data $d$ and the error rates $\alpha$ and $\beta$ is
\begin{align*}
    \prod_{c \in C}\prod_{g \in G} \mathbb{P}_{(\alpha, \beta)}(D(c, g) = d(c, g) \mid E(c, g) = e_{(T, \sigma)}(c, g))
\end{align*}
Since pairs of $(c, g) \in C \times G$ with $d(c, g) = ?$ are ignored, the probabilities in the product above are always set to 1. As stated before, the goal is now to find the tuple $(T, \sigma, \alpha, \beta)$ with the highest likelihood.

\section{Algorithm introduction}

\ac{scite} is a \ac{mcmc} algorithm. A Monte Carlo algorithm runs a random experiment that produces possible solutions to a problem and evaluates how well the generated solutions solve the problem. This operation of generating and evaluating a solution is then repeated multiple times and the result is the best solution the algorithm has encountered. In theory, it would suffice if the experiment had a probability greater than zero to produce a good solution, but in order to improve the solution quality and to reduce the required repetitions, one would use an experiment that produces the best solutions with a higher probability than worse solutions and that can be repeated quickly. As the name implies, \ac{mcmc} algorithms simulate a Markov Chain to produce solutions. The advantage of using Markov Chains is that the next sample may depend on the previous one. The algorithm may therefore introduce small changes to the solution. This is obviously faster than generating a new solution from scratch and if the current sample is already a good solution, the change may preserver some of its quality. However, a designer of a \ac{mcmc} algorithm has to make sure that the chain actually converges on the desired distribution.