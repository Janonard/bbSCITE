\section{Identified challenges}

The biggest source of computational power for \acp{FPGA} is loop pipelining and unrolling: With pipelining, multiple parts of a loop's body instructions are placed in a chain separated by registers. These pipeline stages can work independently from each other and if done correctly, a perfectly pipelined loop can processes as many trips in parallel as it has stages and complete a trip every clock cycle. Unrolling is the replication of these loop bodies so even more trips can be processed in parallel. Loop pipelining and unrolling can be combined and are therefore often called deep and wide parallelization, respectively.

\ac{SCITE} offers multiple opportunities for deep and wide parallelization: First, one simulation often simulates multiple chains to average out the effect of the random, initial solutions. Second, simulating a chain requires the repeated proposal and evaluation of steps. The simplest solution would be to merge these two loops into one and implement the body as a single, continuous, perfectly pipelined and replicable block. However, there a multiple nested loops in \ac{SCITE}'s loop body that may prevent pipelining due to their unpredictable or dynamic bounds. For example, one such loop is the tree traversal where the algorithm traverses up or down a tree to identify the ancestors or descendants of a node. In theory, this loop would be bounded by the (possibly static) tree size, but it may be able to finish earlier. Therefore, it might be reasonable to partition the loop body into multiple kernels as done by Bozgan in their master's thesis \cite{bozgan_2019}, but it may also make the design even more complicated.

Next, there are random draws required in multiple different positions in the algorithm. The original implementation uses a single \ac{RNG} for the entirety of the algorithm, which makes every draw uncorrelated to the next. There are different ways to deliver randomness to the \ac{FPGA}. One option may be to precompute random numbers on the Host, store them in a buffer and let the FPGA load them from memory. However, we expect that memory throughput might become a bottleneck for the design and it might be therefore useful to put the \ac{RNG} on the \ac{FPGA}. One option for this might be the Mersenne Twister by Matsumoto and Nishimura \cite{matsumoto1998mersenne}, which is in widely use and \ac{FPGA}-based implementations have been shown to outperform CPU and GPU implementations \cite{tian2009mersenne}. It is therefore a good candidate as a random number source for our implementation. However, it might also be better to implement independend twisters for the different draws in order to reduce dependencies among different parts of the design. Identical twisters with different seeds are however known to produce corelated values. This has been remedied by Matsumoto and Nishimura by providing a \textit{Dynamic Creation} framework \cite{matsumoto2000dynamic} that takes, among others, a twister ID and produces parameter sets for different, independent twister instances, but we don't know if this can be implemented efficiently.

Lastly, there are a lot of exponential and logarithmic functions in the likelihood computation. These are very resource intensive on \acp{FPGA} and we should try to reduce their use as much as possible.
