\section{Identified challenges}

The biggest sources of computational power on \acp{FPGA} is loop pipelining and unrolling: With pipelining, multiple parts of a loop's body instructions are placed in a chain separated by registers and can therefore work independently from each other. If done correctly, a perfectly pipelined loop can processes as many loop trips in parallel as it has stages and complete a trip every clock cycle. Unrolling is the replication of these loop bodies so even more trips can be processed in parallel. Loop pipelining and unrolling are often called deep and wide parallelization, respectively, and can be combined to multiply the parallelity.

\ac{SCITE} offers multiple opportunities for deep and wide parallelization: First, one simulation often simulates multiple chains to average out the effect of the random, initial solutions. Second, simulating a chain requires the repeated proposal and evaluation of steps. Third, there is little inherent feedback within one chain step: The results of a chain step are only feed back to the next step after it has been completed, which means that, for example, the next change can already be proposed while the previous step is still in evaluation. The simplest solution would therefore be to merge the two loops into one and implement the body as a single, continuous, perfectly pipelined and replicable block. This block could then be replicated until the \ac{FPGA} is full, yielding maximum performance. However, there a multiple nested loops in \ac{SCITE}'s loop body that may prevent pipelining due to their unpredictable or dynamic bounds. For example, one such loop is the tree traversal where the algorithm traverses up or down a tree to identify the ancestors or descendants of a node. In theory, this loop would be bounded by the (possibly static) tree size, but it may be able to finish earlier. Therefore, it might be reasonable to partition the loop body into multiple kernels as done by Bozgan in their master's thesis \cite{bozgan_2019}, but it may also make the design even more complicated since the kernel's throughput needs to be synchronized.

Another common challenge in \ac{FPGA} design development is memory management. \acp{FPGA} have direct access to external memory and developers therefore need to setup custom cache structures for their access patterns. There are two relevant points where memory management may become a problem: Loading and storing the state of the chains, and iterating over the mutation data. However, these points appear to be rather modest:

The chain state consist of multiple scalar values (e.g. the current likelihood score or the error rates) and the mutation tree. The reference implementation uses a parent vector to encode the mutation tree. This is an index array with an element for every node where each element contains the index of its parent. Since C++ allows the use of arbitrarily precise integers scaled to the required size using scalar template parameters, we can save space by introducing an arbitrary, but runtime-static upper bound for the number of nodes. The example data published with \ac{SCITE} uses up to 78 genes and if we for example bound the tree sizes to 128 nodes, we only need 7-bit indices and 112 bytes to store the full array. We therefore assume that it suffices to store the state of a chain in a single structure of static size, which can be quickly loaded from global memory, passed down the pipeline in registers and stored again.

The mutation data is encoded as a matrix with a row for every gene, a column for every cell and entries in $\{0, 1, 2\}$. The entry $2$ corresponds to the $?$-status where the mutation status of a cell-gene combination is not known. We can use 2-bit integers to encode the entries and the example data has up to 78 genes and 1024 cells. This matrix would therefore only be roughly 20 kB big, but even a matrix with 128 genes and 10,000 cells would only take up roughly 328 kB. This is well within the range of what on-chip RAM caches can achieve. We therefore assume that it suffices to load the mutation data to on-chip RAM once during startup and reuse it for every evaluation.

Apart from the classic \ac{FPGA} challenges, there are also challenges specific to Monte Carlo Algorithms: There are random draws required in multiple different positions in the algorithm, which conflicts with the deterministic nature of \acp{FPGA}. One option to produce random numbers might be the Mersenne Twister by Matsumoto and Nishimura \cite{matsumoto1998mersenne}, which is already widely used and \ac{FPGA}-based implementations have also been shown to outperform CPU and GPU implementations \cite{tian2009mersenne}. It might also be beneficial to implement independent twisters for the different draws in order to reduce feedback and dependencies in the design. Identical twisters with different seeds are however known to produce correlated values, which has been remedied by Matsumoto and Nishimura by providing a ''Dynamic Creation'' framework \cite{matsumoto2000dynamic}. It takes, among others, an ID as an input and outputs parameter sets for different, independent \ac{RNG} instances, but we have not evaluated yet whether this can be implemented efficiently. Apart from that, we also have not found an open-sourced C++ implementation of the Mersenne Twister optimized for FPGAs yet, which may require use to implement it ourselves.

Lastly, there are a lot of exponential and logarithmic functions in the likelihood computation. These are very resource intensive on \acp{FPGA} and we should therefore try to reduce their use as much as possible.
